
########################################################################
# ${ML_INSTALL_ prepended variables are replaced during installation   #
########################################################################
substitutions:
  # Substitutions can be used like BASH variables
  # THEY MUST BE WRAPPED IN ${} - ${THIS_WILL_WORK}
  # Order matters!
  DATA_DIR: ${ML_INSTALL_DATA_DIR}
  TMP_DIR: ${ML_INSTALL_TMP_DIR}
  CFG_DIR: ${ML_INSTALL_CFG_DIR}
  LOGGING_DIR: ${ML_INSTALL_LOGGING_DIR}
  MODEL_DIR: ${ML_INSTALL_MODEL_DIR}

  # This file contains substitutions that will be imported into this file (secrets)
  # NOTE: The 'IncludeFile' directive must be contained in the 'substitutions' section
  IncludeFile: ${ML_INSTALL_CFG_DIR}/secrets.yml

  # --------- Example
  EXAMPLE99: "World!"
  # It is a good idea to quote your values,
  # especially if they contain spaces/semicolons/exclamations/etc
  EXAMPLE_PASSWORD99: "string!with#chars:that&may*cause^issues.if,'unquoted'"
  # You can nest substitutions as long as they are specified in logical order
  EXAMPLE_NESTED_SUBSTITUTION: "Hello, ${EXAMPLE99}. Here is a password: ${EXAMPLE_PASSWORD99}"
  EXAMPLE_FAIL: "This will fail because ${EXAMPLE_FOR_SINGLE_QUOTES} is not defined yet"

  EXAMPLE_FOR_DOUBLE_QUOTES: 'I would like to use "double quotes" in a string'
  EXAMPLE_FOR_SINGLE_QUOTES: "I would like to use 'single quotes' in a string"

THIS IS AN EXAMPLE:
  of substitution variables: "Hello, ${EXAMPLE99}. Here is a password: ${EXAMPLE_PASSWORD99}"

system:
  # Path where the system will store configuration files
  config_path: ${CFG_DIR}
  # Path where the system will store variable data (tokens, serialized data, etc)
  variable_data_path: ${DATA_DIR}
  # Path where temp files will be stored
  tmp_path: ${TMP_DIR}
  # Path where various images will be stored
  image_dir: ${DATA_DIR}/images
  # Path where the ML model folder structure will be stored
  model_dir: ${MODEL_DIR}
  # Maximum threaded processes, adjust to your core count and load.
  thread_workers: 4

server:
  # Set interface IP to listen on, 0.0.0.0 will listen on all IPv4 interfaces
  address: ${ML_INSTALL_SERVER_ADDRESS}
  port: ${ML_INSTALL_SERVER_PORT}
  jwt:
    #  the secret key that will be used to sign JWT tokens. (WIP!!!)
    #  ***MAKE SURE YOU CHANGE THE DEFAULT VALUE when this is implemented***
    # If you change the key after signing tokens, those existing tokens will be invalid
    sign_key: ${JWT_SIGN_PHRASE}
    #  the algorithm to use for signing JWT tokens. The default is HS256.
    # BE AWARE if you change this after signing tokens, tokens signed with old algo will be invalid
    algorithm: HS256

logging:
  # Logging levels are: debug, info, warning, error, critical
  # Root logging level
  level: ${ML_INSTALL_LOGGING_LEVEL}

  sanitize:
  # Try to sanitize tokens, keys, passwords, usernames, host and ip addresses from logs
    enabled: yes
    replacement_str: <sanitized>
  console:
  # log to console aka stdout
    enabled: ${ML_INSTALL_LOGGING_CONSOLE_ENABLED}
    # Per module logging level
#    level: debug
  syslog:
    enabled: ${ML_INSTALL_LOGGING_SYSLOG_ENABLED}
    #    level: debug
#    address: /dev/log
    address: ${ML_INSTALL_LOGGING_SYSLOG_ADDRESS}
  # log to file
  file:
    enabled: ${ML_INSTALL_LOGGING_FILE_ENABLED}
#    level: debug
    # directory where log files will be stored
    path: ${LOGGING_DIR}
    # prefix logname with this string, 'zmml' will become zmml_m1.log for monitor 1
    filename_prefix: zmmlS
    # Do not suffix logs with monitor id, log everything to a single file (Leave blank to disable)
    # If this has a value, filename_prefix is ignored.
    file_name:
    # override log file owner and group
    # user:
    # group:

locks:
  # Dis/En-able file locking (Default: yes)
#  enabled: no
  # override where lock files are stored
  dir: ${DATA_DIR}/locks
  gpu:
    # Max number of parallel processes (Default: 1)
    max: 3
    # Timeout for acquiring lock (Default: 30)
    timeout: 35
  cpu:
    # Stay tuned for OpenVINO support for Intel CPU/GPU/iGPU
    max: 2
    timeout: 24
  tpu:
    # Unexpected results may occur when max > 1
    max: 1
    timeout: 13

# Define what models the server will offer
models:
    - name: aws
      description: "AWS Rekognition remote HTTP detection (PAID pre request!)"
      enabled: no
      framework: http
      model_type: object
      processor: none
      sub_framework: rekognition

      detection_options:
        confidence: 0.4455

    - name: virel
      description: "virel.ai remote HTTP detection (FREE atm but will be PAID)"
      enabled: no
      framework: http
      model_type: object
      processor: none
      sub_framework: virel

      detection_options:
        confidence: 0.4567

    # name is normalized to lowercase, spaces are preserved.
    # name is used to call the model via the API
    - name: tpu1
      description: "SSD MobileNet V2 TensorFlow2 trained"
      enabled: no
      framework: coral
      model_type: object
      processor: tpu

      input: "${MODEL_DIR}/coral_tpu/tf2_ssd_mobilenet_v2_coco17_ptq_edgetpu.tflite"
      # All of the included TPU object detection models require the 90 label COCO dataset
      # See https://coral.ai/models/object-detection/
      classes: "${MODEL_DIR}/coral_tpu/coco-labels-paper.txt"

      detection_options:
        # Non Max Suppressive threshold, lower will filter more overlapping bounding boxes out.
        # Currently, only TPU model NMS can be enabled/disabled
        nms:
          # Enable Non Max Suppression
          enabled: yes
          threshold: .35
        # Only return results >=
        confidence: 0.2

    # An example of an OpenCV YOLO model, name is what you will use to call the model
    - name: YOLOv4 Tiny  # Name is converted to lowercase; 'yolov4 tiny'
      enabled: true  # Optional. Defaults to True.
      description: "yolov4 Tiny pretrained DarkNet model"  # Optional; metadata.
      framework: opencv  # REQUIRED. Defaults to opencv/yolo.
#      framework: opencv
      # sub_framework can come in handy to possibly tune your model for a specific framework. opencv has different "readers" for models
      # darknet is the default, but you can also use onnx, caffe, etc. See the OpenCV docs for more info.
      sub_framework: darknet  # An example usage is for opencv framework, darknet/onnx/caffe are subsets of opencv.
      model_type: object # REQUIRED. Defaults to object - object/face/alpr (for identification).
      processor: cpu  # Optional. Defaults to cpu - cpu/gpu/tpu.
      square: yes

      input: "${MODEL_DIR}/yolo/yolov4-tiny.weights"  # REQUIRED - Model file.
      config: "${MODEL_DIR}/yolo/yolov4-tiny.cfg"  # Optional - .weights requires .cfg, .onnx and .tflite does not.

      detection_options:
        # Non Max Suppressive threshold, lower will filter more overlapping bounding boxes out.
        nms: 0.3
        # Only return results >=
        confidence: 0.2

    - name: YOLOv4
      enabled: no  # Optional. Defaults to True.
      description: "yolov4 pretrained DarkNet model"  # Optional.
      framework: yolo  # Optional. Defaults to yolo.
      model_type: object # Optional. Defaults to object - object/face/alpr (for identification).
      processor: cpu  # Optional. Defaults to cpu - cpu/gpu/tpu.

      input: "${MODEL_DIR}/yolo/yolov4_new.weights"  # Required if yolo framework.
      config: "${MODEL_DIR}/yolo/yolov4_new.cfg"  # Optional (.weights requires .cfg, .onnx and .tflite does not).
#      classes: "${MODEL_DIR}/coco.names"  # Optional. Default is COCO 2017 classes.

      # Image will be resized to these dimensions before being passed to the model
      height: 512  # Optional. Defaults to 416.
      width: 512  # Optional. Defaults to 416.
      # Square the image by zero-padding the shorter side to match the longer side before resize
      square: no  # Optional. Defaults to False.
      # EXPERIMENTAL!  - Only for OpenCV CUDA YOLO models - half precision FP16 target
      # WIP!!!
      cuda_fp_16: false  # Optional. Defaults to False.

      detection_options:
        # The model will only return detections with a confidence score higher than this
        confidence: 0.2  # Optional. Defaults to 0.2.
        # Non Max Suppression threshold. Higher values will remove more overlapping boxes
        nms: 0.4  # Optional. Defaults to 0.4.

    - name: YOLOv4-P6
      enabled: false
      processor: cpu  # Optional. Defaults to cpu - cpu/gpu/tpu.
      input: "${MODEL_DIR}/yolo/yolov4-p6.weights"
      config: "${MODEL_DIR}/yolo/yolov4-p6.cfg"
      description: "Scaled YOLO v4-P6 pretrained DarkNet 1280x1280"
      height: 1280
      width: 1280

    - name: yolov7 tiny
      processor: cpu  # Optional. Defaults to cpu - cpu/gpu/tpu.
      description: "yolov7 tiny pretrained DarkNet model"
      input: "${MODEL_DIR}/yolo/yolov7-tiny.weights"
      config: "${MODEL_DIR}/yolo/yolov7-tiny.cfg"
      square: yes

    - name: yolov7
      processor: cpu  # Optional. Defaults to cpu - cpu/gpu/tpu.
      enabled: no
      description: "YOLO v7 pretrained DarkNet model"
      input: "${MODEL_DIR}/yolo/yolov7.weights"
      config: "${MODEL_DIR}/yolo/yolov7.cfg"
      square: yes
      height: 640
      width: 640

    - name: yolov7x
      processor: cpu  # Optional. Defaults to cpu - cpu/gpu/tpu.
      enabled: no
      description: "YOLO v7-X pretrained DarkNet model"
      input: "${MODEL_DIR}/yolo/yolov7x.weights"
      config: "${MODEL_DIR}/yolo/yolov7x.cfg"
      square: yes
      height: 640
      width: 640

#    - name: dlib face
#      description: "dlib face model"
#      model_type: face
#      framework: face_recognition
#
#      detection_model: cnn
#      training_model: cnn
#      train_max_size: 500
#      unknown_face_name: "Unknown"
#      unknown_faces_leeway_pixels: 10
#      unknown_faces_dir: "${DATA_DIR}/unknown_faces"
#      known_faces_dir: "${DATA_DIR}/known_faces"
#
#      detection_options:
#        confidence: 0.5
#        upsample_times: 1
#        num_jitters: 1
#        max_size: 600
#        recognition_threshold: 0.6

#    - name: "openalpr local cpu"
#      description: "openalpr local SDK (binary) model"
#      model_type: alpr
#      framework: alpr
##      processor: cpu
#
#      service: openalpr
#      api_type: local
##      api_url: "http://localhost:8080"
##      api_key: "sk_1234567890"
#
#      detection_options:
#        alpr_binary: alpr
##        alpr_binary_params:
#        confidence: 0.5
#        max_size: 600
#
#    - name: "openalpr local gpu"
#      description: "openalpr local SDK (binary) GPU CUDA model"
#      model_type: alpr
#      framework: alpr
#      processor: gpu
#
#      service: openalpr
#      api_type: local
##      api_url: "http://localhost:8080"
##      api_key: "sk_1234567890"
#
#      detection_options:
#        alpr_binary: alpr
#        alpr_binary_params: -GPU
#        confidence: 0.5
#        max_size: 600
#
#    - name: "openalpr cloud"
#      description: "openalpr cloud API model"
#      model_type: alpr
#      framework: alpr
#      processor: cpu
#
#      service: openalpr
#      api_type: cloud
##        api_url: "https://api.openalpr.com/v2/recognize_bytes"
#      api_key: "sk_1234567890"
#
#      detection_options:
#          confidence: 0.5
#          max_size: 600
##          recognize_vehicle: yes
##          country: us
##          state: ca
#
#    - name: 'Platerecognizer cloud'
##      enabled: no
#      model_type: alpr
#      framework: alpr
#      service: plate_recognizer
#      api_type: cloud
##      api_url: "https://api.platerecognizer.com/v1/plate-reader/"
#      api_key: someAPIkeyHERE123
#      detection_options:
##        regions:
#        stats: no
#        min_dscore: 0.5
#        min_score: 0.5
#        max_size: 1600
#
#        payload:
#          regions: ['us']
#          camera_id: 12
#
#        config:
#          region: 'strict'
#          mode:  'fast'