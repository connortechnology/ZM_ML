
########################################################################
# ${ML_INSTALL_ prepended variables are replaced when using install.sh #
########################################################################
substitutions:
  # Substitutions can be used like BASH variables
  # THEY MUST BE WRAPPED IN ${} - ${THIS_WILL_WORK} $THIS_WONT
  # Order matters!
  DATA_DIR: ${ML_INSTALL_DATA_DIR}
  TMP_DIR: ${ML_INSTALL_TMP_DIR}
  CFG_DIR: ${ML_INSTALL_CFG_DIR}
  LOGGING_DIR: ${ML_INSTALL_LOGGING_DIR}
  MODEL_DIR: ${ML_INSTALL_MODEL_DIR}

  # This file contains substitutions that will be imported into this file (secrets)
  # NOTE: The 'IncludeFile' directive must be contained in the 'substitutions' section
  IncludeFile: ${ML_INSTALL_CFG_DIR}/secrets.yml

  # --------- Example
  EXAMPLE: "World!"

THIS IS AN EXAMPLE:
  of substitution variables: "Hello, ${EXAMPLE}"

system:
  # Path where the system will store configuration files
  config_path: ${CFG_DIR}
  # Path where the system will store variable data (tokens, serialized data, etc)
  variable_data_path: ${DATA_DIR}
  # Path where temp files will be stored
  tmp_path: ${TMP_DIR}
  # Path where various images will be stored
  image_dir: ${DATA_DIR}/images
  # Path where the ML model folder structure will be stored
  model_dir: ${MODEL_DIR}
  # Maximum threaded processes, adjust to your core count and load.
  thread_workers: 4

server:
  # Set interface IP to listen on, 0.0.0.0 will listen on all IPv4 interfaces
  address: ${ML_INSTALL_SERVER_ADDRESS}
  port: ${ML_INSTALL_SERVER_PORT}
  jwt:
    #  the secret key that will be used to sign JWT tokens. (WIP!!!)
    #  ***MAKE SURE YOU CHANGE THE DEFAULT VALUE when this is implemented***
    # If you change the key after signing tokens, those existing tokens will be invalid
    sign_key: ${JWT_SIGN_PHRASE}
    #  the algorithm to use for signing JWT tokens. The default is HS256.
    # BE AWARE if you change this after signing tokens, tokens signed with old algo will be invalid
    algorithm: HS256

logging:
  # Logging levels are: debug, info, warning, error, critical
  # Root logging level
  level: ${ML_INSTALL_LOGGING_LEVEL}

  sanitize:
  # Try to sanitize tokens, keys, passwords, usernames, host and ip addresses from logs
    enabled: yes
    replacement_str: <sanitized>
  console:
  # log to console aka stdout
    enabled: ${ML_INSTALL_LOGGING_CONSOLE_ENABLED}
    # Per module logging level
#    level: debug
  syslog:
    enabled: ${ML_INSTALL_LOGGING_SYSLOG_ENABLED}
    #    level: debug
#    address: /dev/log
    address: ${ML_INSTALL_LOGGING_SYSLOG_ADDRESS}
  # log to file
  file:
    enabled: ${ML_INSTALL_LOGGING_FILE_ENABLED}
#    level: debug
    # directory where log files will be stored
    path: ${LOGGING_DIR}
    # File name for the log file
    file_name: zmmlServer.log
    # override log file owner and group
    # user:
    # group:

locks:
  # Disable/enable file locking (Default: yes)
  #enabled: no
  # Where to store lock files (Default: ${DATA_DIR}/locks)
  dir: ${DATA_DIR}/locks
  gpu:
    # Max number of parallel processes (Default: 1)
    max: 3
    # Timeout for acquiring lock (Default: 30)
    timeout: 35
  cpu:
    max: 2
    timeout: 24
  tpu:
    # Unexpected results may occur when max > 1
    max: 1
    timeout: 13

# -- Define what models the server will offer
models:
  # -- The model name is how you will call it in the API request
  - name: YOLOv4  # Name will be lower cased, spaces are preserved; 'yolov4'
    enabled: no  # Optional. Defaults to True.
    description: "yolov4 pretrained DarkNet model"  # Optional, for user reference.
    # opencv, coral, face_recognition, alpr, http
    framework: opencv  # Optional. Defaults to opencv.
    # -- sub_framework is the various backends the framework can make use of
    # -- darknet is the default for opencv, but you can also use onnx, caffe, etc.
    # -- See the OpenCV docs and ZM ML wiki for more info.
    sub_framework: darknet  # Optional, defaults to darknet for opencv. (onnx, caffe, etc.) **WIP**
    # -- object/face/alpr (for identification)
    model_type: object # Required. Defaults to object
    # -- cpu/gpu/tpu, for now.
    processor: cpu  # Optional. Defaults to cpu

    # -- Model file is required for models that require input.
    # -- Config file is optional, only some models require it.
    input: "${MODEL_DIR}/yolo/yolov4_new.weights"  # Optional. This is the model file itself.
    config: "${MODEL_DIR}/yolo/yolov4_new.cfg"  # Optional (.weights requires .cfg, .onnx and .tflite does not).
    #classes: "${MODEL_DIR}/coco.names"  # Optional. Default is COCO 2017 classes.
    # -- Image will be resized to these dimensions before being passed to the model.
    # -- what was the model trained on? 416x416? 512x512? 1024x1024?
    height: 512  # Optional. Defaults to 416.
    width: 512  # Optional. Defaults to 416.
    # -- Square the image by zero-padding the shorter side to match the longer side before resize
    # -- 1920x1080 -> 1920x1920 with a black bg where the new pixels are
    square: no  # Optional. Defaults to False.

    # -- Options that are specific to the framework and sub_framework
    # -- These options can be changed by API calls.
    detection_options:
      # -- The model will only return detections with a confidence score higher than this
      # -- The client can filter by confidence further, but this is a good starting point to reduce noise.
      confidence: 0.2  # Optional. Defaults to 0.2.
      # -- Non Max Suppression threshold. Higher values will remove more overlapping boxes
      nms: 0.4  # Optional. Defaults to 0.4.

  - name: YOLOv4 Tiny  # Name is converted to lowercase, spaces are preserved; 'yolov4 tiny'
    enabled: true
    model_type: object
    description: "yolov4 Tiny pretrained DarkNet model"
    processor: cpu
    input: "${MODEL_DIR}/yolo/yolov4-tiny.weights"
    config: "${MODEL_DIR}/yolo/yolov4-tiny.cfg"
    detection_options:
      nms: 0.3
      confidence: 0.2

  - name: tpu
    description: "SSD MobileNet V2 TensorFlow2 trained"
    enabled: no

    framework: coral
    sub_framework: none
    model_type: object
    # -- Change to TPU!
    processor: tpu

    input: "${MODEL_DIR}/coral_tpu/tf2_ssd_mobilenet_v2_coco17_ptq_edgetpu.tflite"
    # -- All of the included TPU object detection models require the 90 label COCO dataset
    # -- See https://coral.ai/models/object-detection/
    classes: "${MODEL_DIR}/coral_tpu/coco-labels-paper.txt"

    detection_options:
      # -- Non Max Suppressive threshold, lower will filter more overlapping bounding boxes out.
      # -- Currently, only TPU model NMS can be enabled/disabled
      nms:
        enabled: yes
        threshold: .35
      confidence: 0.2

  - name: aws
    description: "AWS Rekognition remote HTTP detection (PAID per request!)"
    enabled: no
    framework: http
    sub_framework: rekognition
    model_type: object
    processor: none

    detection_options:
      confidence: 0.4455

  - name: virel
    description: "virel.ai remote HTTP detection (FREE atm but will be PAID)"
    enabled: no
    framework: http
    sub_framework: virel
    model_type: object
    processor: none

    detection_options:
      confidence: 0.456

  - name: YOLOv4-P6  # yolov4-p6
    enabled: false
    processor: cpu  # Optional. Defaults to cpu - cpu/gpu/tpu.
    input: "${MODEL_DIR}/yolo/yolov4-p6.weights"
    config: "${MODEL_DIR}/yolo/yolov4-p6.cfg"
    description: "Scaled YOLO v4-P6 pretrained DarkNet 1280x1280"
    height: 1280
    width: 1280

    detection_options:
      confidence: 0.65


  - name: yolov7 tiny
    enabled: yes
    description: "yolov7 tiny pretrained DarkNet model - good for low powered cpu"
    input: "${MODEL_DIR}/yolo/yolov7-tiny.weights"
    config: "${MODEL_DIR}/yolo/yolov7-tiny.cfg"

    detection_options:
      confidence: 0.4

  - name: yolov7
    processor: cpu  # Optional. Defaults to cpu - cpu/gpu/tpu.
    enabled: no
    description: "YOLO v7 pretrained DarkNet model"
    input: "${MODEL_DIR}/yolo/yolov7.weights"
    config: "${MODEL_DIR}/yolo/yolov7.cfg"
    square: yes
    height: 640
    width: 640

    detection_options:
      confidence: 0.5


  - name: yolov7x
    processor: cpu  # Optional. Defaults to cpu - cpu/gpu/tpu.
    enabled: no
    description: "YOLO v7-X pretrained DarkNet model"
    input: "${MODEL_DIR}/yolo/yolov7x.weights"
    config: "${MODEL_DIR}/yolo/yolov7x.cfg"
    square: yes
    height: 640
    width: 640

    detection_options:
      confidence: 0.5

  - name: dlib face
    enabled: no
    description: "dlib face detection/recognition model"
    model_type: face
    framework: face_recognition

    # -- These options only apply to when the model is
    # -- used for training faces to be recognized
    training_options:
      # 'cnn' is more accurate but slower on CPUs. 'hog' is faster but less accurate
      # NOTE: if you use cnn here you MUST use cnn for detection
      model: cnn
      # How many times to upsample the image looking for faces.
      # Higher numbers find smaller faces but take longer.
      upsample_times: 1
      # How many times to re-sample the face when calculating encoding.
      # Higher is more accurate, but slower (i.e. 100 is 100x slower)
      num_jitters: 1
      # Max width of image to feed the model (scaling applied)
      max_size: 600
      # Source dir where known faces are stored.
      dir: "${DATA_DIR}/known_faces"

    # -- An unknown face is a detected face that does not match any known faces
    # -- Can possibly use the unknown face to train a new face
    unknown_faces:
      enabled: yes
      # The label to give an unknown face
      label_as: "Unknown"
      # When cropping an unknown face from the frame, how many pixels to add to each side
      leeway_pixels: 10
      # Where to save unknown faces
      dir: "${DATA_DIR}/unknown_faces"

    detection_options:
      # 'cnn' is more accurate but slower on CPUs. 'hog' is faster but less accurate
      model: cnn

      # confidence threshold for face DETECTION
      confidence: 0.5

      # How sure the model needs to be to classify a face as a known face
      recognition_threshold: 0.6

      # How many times to upsample the image looking for faces.
      # Higher numbers find smaller faces but take longer.
      upsample_times: 1

      # How many times to re-sample the face when calculating encoding.
      # Higher is more accurate, but slower (i.e. 100 is 100x slower)
      num_jitters: 1

      # Max width of image to feed the model (scaling applied)
      max_size: 600



  - name: "openalpr cpu"
    ## NOTE: OpenALPR is fairly powerful for being older.
    ## You need to understand how to skew and warp images to make a plate readable by OCR.
    ## You can also customize openalpr config files and only run them on certain cameras.
    description: "openalpr local SDK (binary) model with a config file for CPU"
    enabled: no


    model_type: alpr
    framework: alpr
    processor: none
    sub_framework: openalpr

    detection_options:
      binary_path: alpr
      # The default config file uses CPU, no need to make a custom config file
      binary_params:
      confidence: 0.5
      max_size: 600

  - name: "openalpr gpu"
    description: "openalpr local SDK (binary) with a config file to use CUDA GPU"
    enabled: no

    model_type: alpr
    framework: alpr
    sub_framework: openalpr
    # openalpr config file controls processor, you can put none,cpu,gpu or tpu here.
    processor: none

    detection_options:
      # path to alpr binary (default: alpr)
      binary_path: alpr
      # Make a config file that uses the gpu instead of cpu
      binary_params: "--config /etc/alpr/openalpr-gpu.conf"
      confidence: 0.5
      max_size: 600

  - name: 'Platerec'  # The model name is normalized by lower casing, spaces are preserved; 'platerec'
    enabled: no
    model_type: alpr
    framework: http
    sub_framework: plate_recognizer

    api_type: cloud
    #api_url: "https://api.platerecognizer.com/v1/plate-reader/"
    api_key: ${PLATEREC_API_KEY}
    detection_options:
      # Only look in certain countrys or regions in a country.
      # See platerecognizer docs for more info
      #regions: ['ca', 'us']

      stats: no

      min_dscore: 0.5

      min_score: 0.5

      max_size: 1600

      # For advanced users, you can pass in any of the options from the API docs
      #payload:
        #regions: ['us']
        #camera_id: 12

      #config:
        #region: 'strict'
        #mode:  'fast'
