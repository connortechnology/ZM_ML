#This is an example of the config that the actual ZM detection script will use
#Keys are case-sensitive!

substitutions:
  # Order matters!
  DATA_DIR: ${ML_INSTALL_DATA_DIR}
  TMP_DIR: ""
  CFG_DIR: ${ML_INSTALL_CFG_DIR}
  LOGGING_DIR: ${ML_INSTALL_LOGGING_DIR}

  # These will be imported from the file to be used as variables (secrets)
  IncludeFile: "${CFG_DIR}/secrets.yml"

  ROUTE_NAME: ${ML_INSTALL_ROUTE_NAME}
  ROUTE_HOST: ${ML_INSTALL_ROUTE_HOST}
  ROUTE_PORT: ${ML_INSTALL_ROUTE_PORT}
  # --------- Example
  EXAMPLE: "World!"

THIS IS AN EXAMPLE:
  of substitution variables: "Hello, ${EXAMPLE}"

system:
  # Override the default config path [/opt/etc/zm/ml]
  config_path: ${CFG_DIR}
  # Path where the system will store variable data [/opt/var/lib/zm_ml]
  variable_data_path: ${DATA_DIR}
  # Path where temp files will be stored, leave empty to auto-detect
  tmp_path: ${TMP_DIR}
  image_dir: ${DATA_DIR}/images
  # A warning will be printed to logs when the image dir is over this size
  image_dir_warning_size: 150 MB
  # The image dir will start dropping oldest files when it reaches this size
  image_dir_max_size: 300 MB
  # Maximum parallel threaded processes
  thread_workers: 4

zoneminder:
  misc:
    write_notes: yes

  api: ${ZM_API}
  portal: ${ZM_PORTAL}
  user: ${ZM_USER}
  password: ${ZM_PASS}
  # a value of 'no' will allow self-signed certs
  ssl_verify: ${ZM_SSL}

logging:
#  root logging level
  level: debug

  sanitize:
    # Try to sanitize tokens, keys, passwords, usernames, host and ip addresses from logs
    enabled: yes
    replacement_str: <sanitized>

  console:
    # log to console
    enabled: ${ML_INSTALL_LOGGING_CONSOLE_ENABLED}
  #    level: debug

  syslog:
    enabled: ${ML_INSTALL_LOGGING_SYSLOG_ENABLED}
    #    level: debug
#    address: /dev/log
    address: ${ML_INSTALL_LOGGING_SYSLOG_ADDRESS}

  file:
    # log to file
    enabled: ${ML_INSTALL_LOGGING_FILE_ENABLED}
    #    level: debug
    # directory where log files will be stored
    path: ${LOGGING_DIR}
    # log file name
    filename: zm_mlapi.log
    # override log file permissions
    # user:
    # group:


mlapi:
  routes:
    - name: ${ROUTE_NAME}
      enabled: yes  # Default is yes
      weight: 0  # Lower takes precedence
      host: ${ROUTE_HOST}  # Internal IP or hostname (add https:// if TLS encrypted)
      port: ${ROUTE_PORT}
      timeout: 60  # Default: 90
      # Auth is WIP!
      #username: admin
      #password: admin

animations:
  # If you are on a low memory system, write frame buffer to disk instead of holding it in memory
  low_memory: no
  # If an animation file already exists, overwrite it
  overwrite: no
  # Maximum width of the animation (Scaled properly)
  width: 640

  # When the animation is for an event, use the ZM API to get images for the animation
  max_attempts: 3
  attempt_delay: 3

  gif:
    enabled: true
    # Make a 'sped-up' version of the animation (makes the gif show more of an event)
    fast: true

  mp4:
    enabled: true



notifications:
  mqtt:
    #-- use python mqtt client to
    #-- Options to use no encryption or secure/insecure TLS/mTLS
    #-- Default ports: for TCP: non-TLS: 1883  TLS:8883 .
    enabled: no

    #-- Send image to MQTT topic
    image:
      enabled: yes
      topic: "zm_ml/image"

    animation:
      enabled: yes
      topic: "zm_ml/animation"

    # Force mqtt to send pic and data even if it's a PAST event
    force: no

    #-- Allow you to set a custom MQTT topic name, formats for topics are: name/sub-name/sub-sub-name
    #-- notice no leading or trailing '/'
    #-- python mqtt default topic: zm_ml/detection
    #topic:  myown_topic/here

    #-- if using tls remember about host verification (tls_insecure :  no host verification but still encrypted)
    #broker:  brokers.hostname
    broker: ${MQTT_BROKER}

    #-- Only use this if not using standard tcp ports, it defaults to 1883 if no TLS and 8883 if TLS, this setting will override
    #port:  1234

    #-- MQTT Credentials if enabled in broker
    user: ${MQTT_USERNAME}
    pass: ${MQTT_PASSWORD}

    #-- MQTT over TLS
    #-- Location to MQTT broker CA certificate. Uncomment this line will enable MQTT over TLS.
    #-- Strict certificate checking
    #-- [Default: no]
    allow_self_signed: yes

    #-- To allow insecure TLS - disable peer verifier/don't verify hostname in COMMON NAME (CN:  field), [Default: no]
    #-- if using ip address in cert's COMMON NAME field then this needs to be 'yes'
    #-- [Default: no]
    tls_insecure: yes

    #-- mTLS CA (self signed?)
    tls_ca: /path_to/mqtt_certs/ca.crt

    #-- Here is a good guide on setting up a CA and signing server/client certificates for MQTT, even if you're using mqtt over your LAN only,
    #-- it is always good to enable encryption and learn about it -> http://www.steves-internet-guide.com/creating-and-using-client-certificates-with-mqtt-and-mosquitto/
    #-- I DO NOT RECOMMEND using Home Assistant MQTT broker add-on as it's a nightmare to get TLS working. (I am still unable to get the MQTT integration to connect to my broker using TLS)
    #-- I run an MQTT mosquitto broker on my ZM host and hass connects to that over unencrypted connection.
    #-- To enable 2-ways TLS, add client certificate and private key, Meaning you had a CA sign your broker's server key/cert
    #-- and also had the CA sign the client key/cert that you are using here
    #-- Location to client certificate and private key
    tls_cert :  /path_to/mqtt_certs/client-zm.crt
    tls_key :  /path_to/mqtt_certs/client-zm.key


  zmninja:
    enabled: no

    fcm:
    # Default YES - switch to no until ZM team recompiles zmninja with new creds
      v1:
        enabled: no
        # When push messages are sent, your ES sends a message to my cloud function
        # that sends the message to Google's FCM servers. This is the key that authorizes
        # your ES to send messages to my cloud function. By default, it will contain a key
        # that authorizes with my server. If you switch to your own server, change this value
        # You will also need to switch the server URL to your own server, use fcm:v1:url for that
        key:
        url:
      # Location of tokens.txt that the websocket server tracks from zmNinja
      token_file: '${DATA_DIR}/push/tokens.txt'
      # if yes, will replace notifications with the latest one
      replace_messages: no
      # Date format to use when sending notification over push (FCM)
      # For example, a 24 hr format would be
      #date_format: %H:%M, %d-%b
      date_fmt: "%I:%M %p, %d-%b"

      # Set priority for android push.
      # You can set it to high or normal.
      # There is weird foo going on here. If you set it to high,
      # and don't interact with push, users report after a while they
      # get delayed by Google. I haven't quite figured out what is the precise
      # value to put here to make sure it always reaches you. Also make sure
      # you read the zmES faq on delayed push [Default: high]
      android_priority: high

      # Make this yes if you are having push notification issues and want me to
      # take a look at what is going on my server side. Default is no
      # WARNING: If you enable this, I'll get to see your push notification details
      # including your full token and possibly your ZM user and password that you provide
      # as part of the picture URL. I try and automatically replace it, but no guarantees if
      # the regex fails in certain conditions. SO KEEP THIS OFF unless you've chatted with me
      # and you know we have exchanged notes. You should turn this off once debugging is over
      log_raw_message: no

      # If you want me to help you debug what is going wrong in FCM, it helps
      # if you add a unique ID here so that I know what to look for
      # it can be anything. Default is NONE
      log_message_id: I_LOVE_LAMBSHANKS

      # If you see messages not being delivered in doze mode for android
      # Even AFTER you disable battery optimization for the app, try making this 0
      # otherwise leave it unspecified. The value here is in seconds
      # it specifies how long the message will be valid before it is discarded
      # Some reports say if you set this to 0, android will try and deliver it immediately
      # while others say it won't. YMMV.
      android_ttl: 0



  gotify:
    enabled: yes
    # If you are not receiving images in gotify notifications, set this to yes to set image to a publicly available URL
    # This will tell you if your gotify android clients are not able to access your ZM server from outside the LAN
    test_image: no
    host: ${GOTI_HOST}
    # Gotify App token
    token: ${GOTI_TOKEN}
    # Override the ZM Portal URL for gotify image grabbing (useful behind a reverse proxy)
    # say portal is http://zm.example.com/zm due to being on internal network but
    # Gotify needs https://zm.example.com/zm to grab the images.
    portal: ${GOTI_PORTAL}
    # REMEMBER that Gotify grabs the image from a URL instead of having it sent directly to it like pushover does.

    # Show a clickable link to view the event in a browser (only once inside the Gotify App).
    # this is handy if the notification goes out to a device without zmNinja installed.
    # They can just click the link and view the event in a regular browser.
    # -- NOTE: Your ZM server may need to be accessible externally for this to work correctly.

    # !! WARNING: If you use this, you are sending your ZM user and password to the Gotify server/clients,
    # if no SSL is used IT WILL BE CLEAR TEXT! So USE SSL!

    # [Default: no]
    link_url: yes

    # The ZM API user for the clickable URL link in the pushover notification. I HIGHLY recommend HTTPS on your ZM host,
    # making a user with VIEW privileges of stream and events only and using that for push_user and pas
    # -- EXAMPLE: make a user named 'PushView' with VIEW privs only for STREAM and EVENT
    # [Default: None]
    link_user: ${LINKURL_USER}
    link_pass: ${LINKURL_PASS}

    # Control the 'View event in browser' video URL params ->
    # zm.example.com/zm/cgi-bin/nph-zms? ----- continued next line ------
    # mode={_mode}&scale={_scale}&maxfps={_max_fps}&buffer={_buffer}&replay={_replay}
    url_opts:
      # [Default: jpeg]
      mode: jpeg
      # [Default: 50]
      scale: 50
      # [Default: 15]
      max_fps: 15
      # [Default: 1000]
      buffer: 1000
      # [Default: single]
      replay: single

  pushover:
    enabled: no
    # This Pushover app will send a jpeg notification
    token: ${PUSHOVER_TOKEN}
    key: ${PUSHOVER_KEY}

    # PushOver has a monthly limit, 'cooldown' means at least X seconds must have passed since the last push for that monitor
    # i.e: cooldown: 30 means only send a pushover notification if it has been at least 30 seconds since the
    # last SUCCESSFUL pushover notification for that MONITOR
    # [Default: 30]
    cooldown: 30
    # send the message to a specififc device (leave blank to send to all devices)
    # [Default: <Nothing>]
    device:



    animation:
      enabled: no
      # If a gif is being created, send it as a separate pushover animation (Pushover only works with GIF)
      token:
      key:

    # Pushover custom notification sounds!
    # *** NOTE: has to be setup in your pushover account first.
    # *** Meaning you have to upload mp3s and label the sound files with the same name as the sound you want to use.
    sounds:
      # You can override these sounds on a per-monitor basis, see the per monitor examples for how to achieve
      # 'person detected in the front yard' sound for the front yard notification when a person is in the detected objects
      default: motion_detected
      # per object overrides are formatted as such
      person: person_detected
      #    dog: dog_detected
      # custom groups can be specified as such
      #    vehicles: vehicle_detected
      #    animals: animal_detected

    # Show a clickable link to view the event in a browser (only once inside the Pushover App).
    # this is handy if the notification goes out to a device without zmNinja installed.
    # They can just click the link and view the event in a regular browser.
    # -- NOTE: Your ZM server may need to be accessible externally for this to work correctly.

    # !! WARNING: If you use this, you are sending your ZM user and password to the Gotify server/clients,
    # if no SSL is used IT WILL BE CLEAR TEXT! So USE SSL!

    # [Default: no]
    link_url: yes

    # The ZM API user for the clickable URL link in the pushover notification. I HIGHLY recommend HTTPS on your ZM host,
    # making a user with VIEW privileges of stream and events only and using that for link_user and link_pass
    # example: make a user named 'PushView' with VIEW privs only for STREAM and EVENT
    # [Default: None]
    link_user: ${LINKURL_USER}
    link_pass: ${LINKURL_PASS}

    # Control the 'View event in browser' video URL params ->
    # zm.example.com/zm/cgi-bin/nph-zms? ----- continued next line ------
    # mode={_mode}&scale={_scale}&maxfps={_max_fps}&buffer={_buffer}&replay={_replay}
    url_opts:
      # [Default: jpeg]
      mode: jpeg
      # [Default: 50]
      scale: 50
      # [Default: 15]
      max_fps: 15
      # [Default: 1000]
      buffer: 1000
      # [Default: single]
      replay: single

  shell_script:
    enabled: no
    script: ${DATA_DIR}/scripts/notify.sh

label_groups:
  animals:
    - dog
    - cat
    - bird
    - horse
    - mouse
  vehicles:
    - car
    - truck
    - bus
    - motorcycle
    - boat
  # For face detection/recognition
  friends:
    - James
    - Addison

detection_settings:
  models:
    # Default dict of Models that will run if not specified per monitor
    # You can override these settings per monitor
    yolov4:



  # Import the zones defined in ZM
  import_zones: no
  # object must be in one of the zones that triggered the motion event
  # REQUIRES import_zones
  match_origin_zone: no

  images:
    pull_method:
      # Precedence: 1. shm 2. api 3. zmu
      shm: no
      api:
        enabled: yes
        # How many frames per second should be grabbed to run Object Detection on (Default: 1)
        fps: 1
        # ANY of the delay options can be set as xx or xx.yy (int/float)
        attempts: 3  # attempts to grab the requested frame
        delay: 0.2   # delay between failed attempts
        max_frames: 10  # Only grab x frames (Default: Calculated based on event duration and monitor capturing FPS)
        # snapshot is the highest alarmed frame ID and can change during an event
        # This will check if the snapshot frame ID has changed and if so, grab the new snapshot frame
        check_snapshots: yes

      zmu: no

    # Save debug images to disk (Every frame grabbed)
    debug:
      # Shows bounding box of filtered out detections in RED
      enabled: no
      # Where to save the debug images Default: $TMP_DIR/images/debug
      path:

    annotation:
      # Draw zone polygons on image
      zones:
        enabled: no
        # Color of the zone polygon
        color: (255, 255, 255)
        # Thickness of the zone polygon line
        thickness: 2

      # Show which model detected the object
      model:
        enabled: yes
        # Show which processor the model used

        processor: yes

      # Show the confidence level of the detection
      confidence: yes

    training:
      # Save 2 images and a JSON file for matching detections
      enabled: no
      path: /home/<user>/ml/training_images


matching:
  # same as zmeventnotification - first, most, most_unique, union[WIP]
  # Tiebreakers will use the SUM of confidences for the model
  strategy: most

  # If using more than 2 Object type Models (yolov4, tiny-yolov7), try to confirm matches by checking
  #  if the object is in roughly the same place across Models.
  object_confirm: yes

  # Remove matches that seem to be 'in the same place'. Comparison is between the previous detections best match.
  static_objects:
    enabled: no
    # The max difference in the center of the object between previous and current detection
    # expressed as a percentage (0.0 - 1.0 OR 13.6%)
    max_diff: 8%
    labels:
      # The label of the object to check for (label_groups supported)
      - vehicles

  filters:
    # This is globally applied to all monitors but can be overridden on a per-monitor basis
    object:
      min_conf: 0.4
      pattern: "(DEFAULT|car|truck|bus|person|dog|cat)"
      total_max_area: 100%
      total_min_area: 1px
    face:
      pattern: ".*"
    alpr:
      pattern: ".*"
      min_conf: 0.5

monitors:
# Override settings based on which monitor an event was triggered by
  1:
    models:
      # Models to run. Name must match the name of the model obtained from its configuration or the API request
      yolov4:
        enabled: no
        options:
          # options to pass to the model
          # see the model's documentation for options
          # if the model is not enabled, these options will be ignored
          conf: 0.5
          nms:

#      yolov4-p6:
      yolov7 tiny:
#      yolov7:
      yolov7x:

    # Add matching filters for this monitor (inherits/overrides config:matching)
#    object_confirm: no

    static_objects:
      enabled: no
      # -- difference in area between current and previous detection
      difference: 69%
      labels:
        - car
#      ignore_labels:
#        - bird


    zones:
    # -- These are zones that are defined in the config file on top of imported ZoneMinder zones
    # -- If you import ZM zones you can add a ML config for that zone here.
    # -- Example: If the imported zone is named "Front Yard", this would set the ML config for it.
        Front Yard:
          enabled: yes

          # -- Polygon points
          points: 0,2146 3818,2146 3820,1058 2604,426 2526,534 198,466 124,632 8,648
          # -- Used to scale polygon points if the monitor resolution has changed.
          # -- Strings like "1080p" "4k" "4kuhd"("uhd") "720p" are supported or a tuple of (width, height)
          resolution: 4kuhd

          # Currently there are 3 types of ML model groups supported object, face, alpr
          # Zone level matching filters can be set for each type
#          object_confirm: no
#
          static_objects:
            enabled: no
            # -- difference in area between current and previous detection, % or pixel value
            difference: 25%
            labels:
              - vehicles

          filters:
            object:
              pattern: "(person|dog|cat|chewbacca)"
              # -- Per label filtering (label_groups supported)
              # -- Trained faces are labeled with the name of the person
              labels:
                person:
                  min_conf: 0.5
                    # -- The minimum and maximum area of the detection box in pixels or percentage of the zone.
                    # -- (how much of the zone is covered by the detection box)
#                  min_area: 10px
#                  max_area: 10%
                  # -- The minimum and maximum area of the detection box in pixels or percentage of the full image.
                  # -- (how much of the image is covered by the detection box)
#                  total_min_area: 10px
#                  total_max_area: 10%
            face:
              # -- You can specify trained face names here, only pattern supported currently
              pattern: ".*"
              # pattern: "(James|Addison)"
            alpr:
              # -- Only pattern and min_conf supported
              pattern: ".*"
              min_conf: 0.1
  2:
    models:
      # Models to run. Name must match the name of the model obtained from its configuration or the API request
      yolov4:
#      yolov4-p6:
      yolov7 tiny:
#      yolov7:
      yolov7x:
      static_objects:
        enabled: yes
        # -- difference in area between current and previous detection
        difference: 69%
        labels:
          - car
#        ignore_labels:
#          - bird

    zones:
      parking area:
        enabled: yes
        # Polygon points. Use ZM zone editor to draw the polygon and copy the points here
        points: 0,722 1592,94 1920,380 1920,1073 0,1080
        resolution: 1080p
        filters:
          object:
            pattern: "(person|dog|cat|car|truck|bus|bicycle)"
            # -- Per label filtering (label_groups supported)
            # -- Trained faces are labeled with the name of the person
            labels:
              person:
                min_conf: 0.5
                # -- The minimum and maximum area of the detection box in pixels or percentage of the zone.
                # -- (how much of the zone is covered by the detection box)
                min_area: 10px
#                max_area: 10%
                # -- The minimum and maximum area of the detection box in pixels or percentage of the full image.
                # -- (how much of the image is covered by the detection box)
                total_min_area: 10px
#                total_max_area: 10%
          face:
            # -- You can specify trained face names here, only pattern supported currently
            pattern: ".*"
            # pattern: "(James|Addison)"
          alpr:
            # -- Only pattern and min_conf supported
            pattern: ".*"
            min_conf: 0.1
